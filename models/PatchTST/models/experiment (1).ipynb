{"cells":[{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import pandas as _hex_pandas\n","import datetime as _hex_datetime\n","import json as _hex_json"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["hex_scheduled = _hex_json.loads(\"false\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["hex_user_attributes = _hex_json.loads(\"{}\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["hex_timezone = _hex_json.loads(\"\\\"UTC\\\"\")"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["hex_project_id = _hex_json.loads(\"\\\"965f7012-9e09-433f-a10d-b4bc04a1b798\\\"\")"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["hex_project_name = _hex_json.loads(\"\\\"Welcome to Hex!\\\"\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["hex_status = _hex_json.loads(\"\\\"\\\"\")"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["hex_categories = _hex_json.loads(\"[]\")"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# import jinja2\n","# raw_query = \"\"\"\n","#     -- Use SQL to get all food orders from a demo data warehouse\n","#     \n","# \"\"\"\n","# sql_query = jinja2.Template(raw_query).render(vars())"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X\n","y\n","region\n"]}],"source":["from numpy import load\n","\n","data = load('/Users/wuruoyu/Sleep-Staging/data/train_data2_noCoordinates.npz')\n","import pandas as pd\n","lst = data.files\n","for item in lst:\n","    print(item)\n","\n","# only_sweets = orders[orders[\"CATEGORY\"] == \"Sweets\"]\n","# popular_dessert = only_sweets[\"MENU_ITEM\"].mode()[0]\n","# print(f\"The most popular dessert is the {popular_dessert}\")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import torch\n","from transformers import TrainingArguments, Trainer\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import BertTokenizer, BertForSequenceClassification\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["(5491, 1373)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["X = list(data[\"X\"]) + list(data[\"X\"])\n","X = [str(i) for i in X]\n","y = list(data[\"y\"]) + list(data[\"y\"])\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n","X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n","X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","X_train_tokenized.keys()\n","len(X_train),len(X_val)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([  101,  1031,  1017,  1012, 14078,  2620, 23352,  2692,  2509,  2063,\n","          1011,  5757,  1016,  1012,  5139,  2620,  2581, 18827,  2620,  2475,\n","          2063,  1011,  5757,  1011,  1020,  1012,  4008,  2683,  2575,  2581,\n","         23632,  2509,  2063,  1011,  5757,  1012,  1012,  1012,  1020,  1012,\n","          5986,  2620, 22932, 24434,  2487,  2063,  1011,  5718,  1011,  1016,\n","          1012,  3878,  2581,  2581,  2581,  2475,  2063,  1011,  5757,  1017,\n","          1012,  6486, 10790, 22907, 20958,  2063,  1011,  5757,  1033,   102,\n","             0,     0,     0,     0,     0,     0]),\n"," 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0]),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","         0, 0, 0, 0]),\n"," 'labels': tensor(0)}"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Create torch dataset\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx].astype(int))\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","\n","train_dataset = Dataset(X_train_tokenized, [(i - 1)/2 for i in y_train])\n","val_dataset = Dataset(X_val_tokenized, [(i - 1)/2 for i in y_val])\n","\n","train_dataset[5]"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["def compute_metrics(p):\n","    print(type(p))\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(y_true=labels, y_pred=pred)\n","    precision = precision_score(y_true=labels, y_pred=pred)\n","    f1 = f1_score(y_true=labels, y_pred=pred)\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# ! pip install accelerate>=0.26.0\n","# ! pip install -U transformers\n","# Define Trainer\n","\n","args = TrainingArguments(\n","    output_dir=\"output\",\n","    num_train_epochs=10,\n","    per_device_train_batch_size=8\n","\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  3%|▎         | 230/6870 [04:33<2:37:09,  1.42s/it]"]}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 172/172 [00:40<00:00,  4.07it/s]/Users/wuruoyu/anaconda3/envs/transformers/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","100%|██████████| 172/172 [00:41<00:00,  4.19it/s]"]},{"name":"stdout","output_type":"stream","text":["<class 'transformers.trainer_utils.EvalPrediction'>\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/plain":["{'eval_loss': 0.4792148768901825,\n"," 'eval_accuracy': 0.8201019664967225,\n"," 'eval_precision': 0.0,\n"," 'eval_recall': 0.0,\n"," 'eval_f1': 0.0,\n"," 'eval_runtime': 41.3178,\n"," 'eval_samples_per_second': 33.23,\n"," 'eval_steps_per_second': 4.163,\n"," 'epoch': 1.0}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]}],"metadata":{"hex_info":{"author":"Xiang Liu","exported_date":"Wed Dec 04 2024 08:14:59 GMT+0000 (Coordinated Universal Time)","project_id":"965f7012-9e09-433f-a10d-b4bc04a1b798","version":"draft"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":4}
