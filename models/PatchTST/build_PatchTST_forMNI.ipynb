{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load datasets and prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tf_keras as keras\n",
    "\n",
    "from transformers import PatchTSTForClassification, PatchTSTConfig, Trainer, TrainingArguments, TrainerCallback\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.load('/Users/wuruoyu/Sleep-Staging/data/train_data2_noCoordinates.npz')\n",
    "val_data = np.load('/Users/wuruoyu/Sleep-Staging/data/val_data2_noCoordinates.npz')\n",
    "test_data = np.load('/Users/wuruoyu/Sleep-Staging/data/test_data_noCoordinates.npz') \n",
    "output_dir = 'models/PatchTST/'\n",
    "\n",
    "X_train = train_data['X']\n",
    "y_train = train_data['y']\n",
    "X_test = test_data['X']\n",
    "y_test = test_data['y']\n",
    "X_val = val_data['X']\n",
    "y_val = val_data['y']\n",
    "X_train = X_train[:,0:2976]\n",
    "X_test = X_test[:,0:2976]\n",
    "X_val = X_val[:,0:2976]\n",
    "X_train = X_train.reshape(3432, 1, 2976)\n",
    "X_test = X_test.reshape(1144, 1, 2976)\n",
    "X_val = X_val.reshape(1144, 1, 2976)\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNI_to_Huggingface(Dataset):\n",
    "    def __init__(self, X_data, y_data, patch_length=32):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.patch_length = patch_length\n",
    "        \n",
    "        # Compute number of patches per input sequence (3000 / 32 = 93 patches)\n",
    "        self.num_patches = X_data.shape[2] // patch_length  # Assuming each sequence is 3000 long\n",
    "\n",
    "        # Reshape the input data into patches: (batch_size, num_patches, patch_length)\n",
    "        self.X_data = self.X_data.reshape(self.X_data.shape[0], self.patch_length, self.num_patches)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Each sample now has shape (num_patches, patch_length)\n",
    "        return {\n",
    "            'past_values': torch.tensor(self.X_data[idx], dtype=torch.float32),  # Input data\n",
    "            'target_values': torch.tensor(self.y_data[idx], dtype=torch.long)   # Labels\n",
    "        }\n",
    "\n",
    "# Create the dataset instances\n",
    "train_dataset = MNI_to_Huggingface(X_train, y_train, patch_length=32)\n",
    "val_dataset = MNI_to_Huggingface(X_val, y_val, patch_length=32)\n",
    "test_dataset = MNI_to_Huggingface(X_test, y_test, patch_length=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize patchtst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchTSTForClassification(\n",
       "  (model): PatchTSTModel(\n",
       "    (scaler): PatchTSTScaler(\n",
       "      (scaler): PatchTSTStdScaler()\n",
       "    )\n",
       "    (patchifier): PatchTSTPatchify()\n",
       "    (masking): Identity()\n",
       "    (encoder): PatchTSTEncoder(\n",
       "      (embedder): PatchTSTEmbedding(\n",
       "        (input_embedding): Linear(in_features=1, out_features=128, bias=True)\n",
       "      )\n",
       "      (positional_encoder): PatchTSTPositionalEncoding(\n",
       "        (positional_dropout): Identity()\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x PatchTSTEncoderLayer(\n",
       "          (self_attn): PatchTSTAttention(\n",
       "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (dropout_path1): Identity()\n",
       "          (norm_sublayer1): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): GELUActivation()\n",
       "            (2): Identity()\n",
       "            (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          )\n",
       "          (dropout_path3): Identity()\n",
       "          (norm_sublayer3): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): PatchTSTClassificationHead(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (dropout): Identity()\n",
       "    (linear): Linear(in_features=11904, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up PatchTST config\n",
    "config = PatchTSTConfig(\n",
    "    num_targets=4,     # 4 classes for classification\n",
    "    num_input_channels=93,    # Single channel input (as per your reshaped data)\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the PatchTSTForClassification model\n",
    "model = PatchTSTForClassification(config)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customize metrics and number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_compute_metrics(p):\n",
    "    print(type(p))\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    label_names=['stages']\n",
    "\n",
    ")\n",
    "custom_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=custom_compute_metrics\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, evaluate and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429/429 [03:04<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 184.3121, 'train_samples_per_second': 18.621, 'train_steps_per_second': 2.328, 'train_loss': 1.319745257184222, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=429, training_loss=1.319745257184222, metrics={'train_runtime': 184.3121, 'train_samples_per_second': 18.621, 'train_steps_per_second': 2.328, 'total_flos': 39636327684096.0, 'train_loss': 1.319745257184222, 'epoch': 1.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "custom_trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:20<00:00,  6.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_runtime': 20.8742,\n",
       " 'eval_samples_per_second': 54.805,\n",
       " 'eval_steps_per_second': 6.851,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "custom_trainer.save_model(output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
