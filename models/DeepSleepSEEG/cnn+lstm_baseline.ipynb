{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#loading modules and data"
      ],
      "metadata": {
        "id": "y0Oxolwghk76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCEf5YIsdIDq",
        "outputId": "fc0df4eb-629c-41ff-f0f7-46ae542d2660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import torch.optim as optim\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "# connect colab notebook to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data\n",
        "data = np.load('/content/drive/MyDrive/ALL/Research_NS/Sleep/data/MNI_sEEG/train_data_noCoordinates.npz')\n",
        "X = data['X']\n",
        "y = data['y']\n",
        "regions = data['region']"
      ],
      "metadata": {
        "id": "meNoiUv3r9qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = torch.tensor(X, dtype=torch.float32)  # Convert to float32 for input\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)  # Convert to long for class labels\n",
        "\n",
        "# Check the shapes to ensure correctness\n",
        "print(\"X shape:\", X_tensor.shape)\n",
        "print(\"y shape:\", y_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfAzgkp5joeL",
        "outputId": "b4b84724-424d-4480-ea91-be462f9d2373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([4576, 6800])\n",
            "y shape: torch.Size([4576])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[:,0:3000] #sampling rate 100Hz, slice to the first 30s"
      ],
      "metadata": {
        "id": "VhUMR5KsYRmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLpHQ51fY4DY",
        "outputId": "2e5d249c-c89b-4e13-f4e6-dae743865bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4576, 3000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_bands = {\n",
        "    \"delta_freq_range\": [(1, 2)],\n",
        "    \"theta_freq_range\": [(3, 7)],\n",
        "    \"alpha_freq_range\": [(8, 12)],\n",
        "    \"low_beta_freq_range\": [(13, 16)],\n",
        "    \"mid_beta_freq_range\": [(17, 20)],\n",
        "    \"high_beta_freq_range\": [(21, 29)],\n",
        "    \"gamma_freq_range\": [(30, 100)]\n",
        "}\n",
        "# \"full_band_range\": [(0.25, 100)]"
      ],
      "metadata": {
        "id": "zCSqLFbjuSjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# building blocks"
      ],
      "metadata": {
        "id": "QZLEJo_ahp5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "class SEBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None,\n",
        "                 *, reduction=16):\n",
        "        super(SEBasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm1d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(planes, planes, 1)\n",
        "        self.bn2 = nn.BatchNorm1d(planes)\n",
        "        self.se = SELayer(planes, reduction)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.se(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    # for older versions of PyTorch.  For new versions you can use nn.GELU() instead.\n",
        "    def __init__(self):\n",
        "        super(GELU, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.gelu(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "nx6Xo9mpsQ5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class extendedMRCNN(nn.Module):\n",
        "    def __init__(self, afr_reduced_cnn_size):\n",
        "        super(extendedMRCNN, self).__init__()\n",
        "        drate = 0.5\n",
        "        fs = 100\n",
        "\n",
        "        kernel_size1 = int(fs / 0.25)  # delta range\n",
        "        kernel_size2 = int(fs / 5)      # theta range\n",
        "        kernel_size3 = int(fs / 10)     # alpha range\n",
        "        kernel_size4 = int(fs / 20)     # beta range\n",
        "        kernel_size5 = int(fs / 50)     # gamma range\n",
        "\n",
        "        def create_feature_layer(kernel_size):\n",
        "            stride = max(50, round(kernel_size / 8))  # Ensure at least 2\n",
        "            padding = max(0, round(kernel_size / 2)) #\n",
        "\n",
        "            return nn.Sequential(\n",
        "                nn.Conv1d(1, 64, kernel_size=kernel_size, stride=stride, bias=False, padding=padding),\n",
        "                nn.BatchNorm1d(64),\n",
        "                nn.GELU(),\n",
        "                nn.MaxPool1d(kernel_size=8, stride=2, padding=4),\n",
        "                nn.Dropout(drate),\n",
        "                nn.Conv1d(64, 128, kernel_size=8, stride=1, bias=False, padding=4),\n",
        "                nn.BatchNorm1d(128),\n",
        "                nn.GELU(),\n",
        "                nn.Conv1d(128, 128, kernel_size=8, stride=1, bias=False, padding=4),\n",
        "                nn.BatchNorm1d(128),\n",
        "                nn.GELU(),\n",
        "                nn.MaxPool1d(kernel_size=4, stride=4, padding=2)\n",
        "            )\n",
        "\n",
        "        self.features1 = create_feature_layer(kernel_size1)\n",
        "        self.features2 = create_feature_layer(kernel_size2)\n",
        "        self.features3 = create_feature_layer(kernel_size3)\n",
        "        self.features4 = create_feature_layer(kernel_size4)\n",
        "        self.features5 = create_feature_layer(kernel_size5)\n",
        "\n",
        "        self.dropout = nn.Dropout(drate)\n",
        "        self.inplanes = 640\n",
        "        self.AFR = self._make_layer(SEBasicBlock, afr_reduced_cnn_size, 1)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv1d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm1d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.features1(x)\n",
        "        x2 = self.features2(x)\n",
        "        x3 = self.features3(x)\n",
        "        x4 = self.features4(x)\n",
        "        x5 = self.features5(x)\n",
        "        print(f\"x1 shape: {x1.shape}\")\n",
        "        print(f\"x2 shape: {x2.shape}\")\n",
        "        print(f\"x3 shape: {x3.shape}\")\n",
        "        print(f\"x4 shape: {x4.shape}\")\n",
        "        print(f\"x5 shape: {x5.shape}\")\n",
        "\n",
        "        # Concatenate all feature outputs along the channel dimension\n",
        "        x_concat = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
        "        x_concat = self.dropout(x_concat)\n",
        "        x_concat = self.AFR(x_concat)\n",
        "\n",
        "        return x_concat"
      ],
      "metadata": {
        "id": "lhhsm1p4sJIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TContext(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(TContext, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_out[:, -1, :])\n",
        "        return F.log_softmax(out, dim=1)"
      ],
      "metadata": {
        "id": "EbWjSRoz19F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepSleepSEEG(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(DeepSleepSEEG, self).__init__()\n",
        "        num_classes = 4\n",
        "        afr_reduced_cnn_size = 640\n",
        "        self.extendedMRCNN = extendedMRCNN(afr_reduced_cnn_size)\n",
        "        lstm_input_size = afr_reduced_cnn_size  # Output size from extendedMRCNN\n",
        "        hidden_size = 128  # Number of LSTM units\n",
        "        num_layers = 2     # Number of LSTM layers\n",
        "\n",
        "        # Initialize TContext with appropriate parameters\n",
        "        self.TContext = TContext(input_size=lstm_input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get features from extendedMRCNN\n",
        "        x_feat = self.extendedMRCNN(x)\n",
        "\n",
        "        # Pass features through TContext (LSTM)\n",
        "        encoded_features = self.TContext(x_feat)\n",
        "\n",
        "        return encoded_features"
      ],
      "metadata": {
        "id": "48i4sPmR3jao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing (checking) model"
      ],
      "metadata": {
        "id": "hw7GjPh2sNUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extendedMRCNN architecture"
      ],
      "metadata": {
        "id": "56P3asjB3Evx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "afr_reduced_cnn_size = 640  # Adjust based on your architecture requirements\n",
        "model = extendedMRCNN(afr_reduced_cnn_size)\n",
        "summary(model, input_size=(64,1,3000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuUNDTkvj4Wx",
        "outputId": "afbfc329-74cc-47e4-e236-684098f1aa8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 shape: torch.Size([64, 128, 9])\n",
            "x2 shape: torch.Size([64, 128, 9])\n",
            "x3 shape: torch.Size([64, 128, 9])\n",
            "x4 shape: torch.Size([64, 128, 9])\n",
            "x5 shape: torch.Size([64, 128, 9])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "extendedMRCNN                                 [64, 640, 9]              --\n",
              "├─Sequential: 1-1                             [64, 128, 9]              --\n",
              "│    └─Conv1d: 2-1                            [64, 64, 61]              25,600\n",
              "│    └─BatchNorm1d: 2-2                       [64, 64, 61]              128\n",
              "│    └─GELU: 2-3                              [64, 64, 61]              --\n",
              "│    └─MaxPool1d: 2-4                         [64, 64, 31]              --\n",
              "│    └─Dropout: 2-5                           [64, 64, 31]              --\n",
              "│    └─Conv1d: 2-6                            [64, 128, 32]             65,536\n",
              "│    └─BatchNorm1d: 2-7                       [64, 128, 32]             256\n",
              "│    └─GELU: 2-8                              [64, 128, 32]             --\n",
              "│    └─Conv1d: 2-9                            [64, 128, 33]             131,072\n",
              "│    └─BatchNorm1d: 2-10                      [64, 128, 33]             256\n",
              "│    └─GELU: 2-11                             [64, 128, 33]             --\n",
              "│    └─MaxPool1d: 2-12                        [64, 128, 9]              --\n",
              "├─Sequential: 1-2                             [64, 128, 9]              --\n",
              "│    └─Conv1d: 2-13                           [64, 64, 61]              1,280\n",
              "│    └─BatchNorm1d: 2-14                      [64, 64, 61]              128\n",
              "│    └─GELU: 2-15                             [64, 64, 61]              --\n",
              "│    └─MaxPool1d: 2-16                        [64, 64, 31]              --\n",
              "│    └─Dropout: 2-17                          [64, 64, 31]              --\n",
              "│    └─Conv1d: 2-18                           [64, 128, 32]             65,536\n",
              "│    └─BatchNorm1d: 2-19                      [64, 128, 32]             256\n",
              "│    └─GELU: 2-20                             [64, 128, 32]             --\n",
              "│    └─Conv1d: 2-21                           [64, 128, 33]             131,072\n",
              "│    └─BatchNorm1d: 2-22                      [64, 128, 33]             256\n",
              "│    └─GELU: 2-23                             [64, 128, 33]             --\n",
              "│    └─MaxPool1d: 2-24                        [64, 128, 9]              --\n",
              "├─Sequential: 1-3                             [64, 128, 9]              --\n",
              "│    └─Conv1d: 2-25                           [64, 64, 61]              640\n",
              "│    └─BatchNorm1d: 2-26                      [64, 64, 61]              128\n",
              "│    └─GELU: 2-27                             [64, 64, 61]              --\n",
              "│    └─MaxPool1d: 2-28                        [64, 64, 31]              --\n",
              "│    └─Dropout: 2-29                          [64, 64, 31]              --\n",
              "│    └─Conv1d: 2-30                           [64, 128, 32]             65,536\n",
              "│    └─BatchNorm1d: 2-31                      [64, 128, 32]             256\n",
              "│    └─GELU: 2-32                             [64, 128, 32]             --\n",
              "│    └─Conv1d: 2-33                           [64, 128, 33]             131,072\n",
              "│    └─BatchNorm1d: 2-34                      [64, 128, 33]             256\n",
              "│    └─GELU: 2-35                             [64, 128, 33]             --\n",
              "│    └─MaxPool1d: 2-36                        [64, 128, 9]              --\n",
              "├─Sequential: 1-4                             [64, 128, 9]              --\n",
              "│    └─Conv1d: 2-37                           [64, 64, 60]              320\n",
              "│    └─BatchNorm1d: 2-38                      [64, 64, 60]              128\n",
              "│    └─GELU: 2-39                             [64, 64, 60]              --\n",
              "│    └─MaxPool1d: 2-40                        [64, 64, 31]              --\n",
              "│    └─Dropout: 2-41                          [64, 64, 31]              --\n",
              "│    └─Conv1d: 2-42                           [64, 128, 32]             65,536\n",
              "│    └─BatchNorm1d: 2-43                      [64, 128, 32]             256\n",
              "│    └─GELU: 2-44                             [64, 128, 32]             --\n",
              "│    └─Conv1d: 2-45                           [64, 128, 33]             131,072\n",
              "│    └─BatchNorm1d: 2-46                      [64, 128, 33]             256\n",
              "│    └─GELU: 2-47                             [64, 128, 33]             --\n",
              "│    └─MaxPool1d: 2-48                        [64, 128, 9]              --\n",
              "├─Sequential: 1-5                             [64, 128, 9]              --\n",
              "│    └─Conv1d: 2-49                           [64, 64, 61]              128\n",
              "│    └─BatchNorm1d: 2-50                      [64, 64, 61]              128\n",
              "│    └─GELU: 2-51                             [64, 64, 61]              --\n",
              "│    └─MaxPool1d: 2-52                        [64, 64, 31]              --\n",
              "│    └─Dropout: 2-53                          [64, 64, 31]              --\n",
              "│    └─Conv1d: 2-54                           [64, 128, 32]             65,536\n",
              "│    └─BatchNorm1d: 2-55                      [64, 128, 32]             256\n",
              "│    └─GELU: 2-56                             [64, 128, 32]             --\n",
              "│    └─Conv1d: 2-57                           [64, 128, 33]             131,072\n",
              "│    └─BatchNorm1d: 2-58                      [64, 128, 33]             256\n",
              "│    └─GELU: 2-59                             [64, 128, 33]             --\n",
              "│    └─MaxPool1d: 2-60                        [64, 128, 9]              --\n",
              "├─Dropout: 1-6                                [64, 640, 9]              --\n",
              "├─Sequential: 1-7                             [64, 640, 9]              --\n",
              "│    └─SEBasicBlock: 2-61                     [64, 640, 9]              --\n",
              "│    │    └─Conv1d: 3-1                       [64, 640, 9]              410,240\n",
              "│    │    └─BatchNorm1d: 3-2                  [64, 640, 9]              1,280\n",
              "│    │    └─ReLU: 3-3                         [64, 640, 9]              --\n",
              "│    │    └─Conv1d: 3-4                       [64, 640, 9]              410,240\n",
              "│    │    └─BatchNorm1d: 3-5                  [64, 640, 9]              1,280\n",
              "│    │    └─SELayer: 3-6                      [64, 640, 9]              51,200\n",
              "│    │    └─ReLU: 3-7                         [64, 640, 9]              --\n",
              "===============================================================================================\n",
              "Total params: 1,888,448\n",
              "Trainable params: 1,888,448\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 2.64\n",
              "===============================================================================================\n",
              "Input size (MB): 0.77\n",
              "Forward/backward pass size (MB): 74.67\n",
              "Params size (MB): 7.55\n",
              "Estimated Total Size (MB): 82.99\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AttnSleep Architecture"
      ],
      "metadata": {
        "id": "2-Ft3na56wpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AS = AttnSleep()\n",
        "summary(AS, input_size=(64,1,3000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVxWp1RB5vFA",
        "outputId": "4da02d2b-820c-495e-beb7-f8f069e8a502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "AttnSleep                                          [64, 5]                   --\n",
              "├─MRCNN: 1-1                                       [64, 30, 80]              --\n",
              "│    └─Sequential: 2-1                             [64, 128, 64]             197,120\n",
              "│    │    └─Conv1d: 3-1                            [64, 64, 500]             3,200\n",
              "│    │    └─BatchNorm1d: 3-2                       [64, 64, 500]             128\n",
              "│    └─Sequential: 2-6                             --                        (recursive)\n",
              "│    │    └─GELU: 3-3                              [64, 64, 500]             --\n",
              "│    └─Sequential: 2-7                             --                        (recursive)\n",
              "│    │    └─MaxPool1d: 3-4                         [64, 64, 251]             --\n",
              "│    │    └─Dropout: 3-5                           [64, 64, 251]             --\n",
              "│    │    └─Conv1d: 3-6                            [64, 128, 252]            65,536\n",
              "│    │    └─BatchNorm1d: 3-7                       [64, 128, 252]            256\n",
              "│    └─Sequential: 2-6                             --                        (recursive)\n",
              "│    │    └─GELU: 3-8                              [64, 128, 252]            --\n",
              "│    └─Sequential: 2-7                             --                        (recursive)\n",
              "│    │    └─Conv1d: 3-9                            [64, 128, 253]            131,072\n",
              "│    │    └─BatchNorm1d: 3-10                      [64, 128, 253]            256\n",
              "│    └─Sequential: 2-6                             --                        (recursive)\n",
              "│    │    └─GELU: 3-11                             [64, 128, 253]            --\n",
              "│    └─Sequential: 2-7                             --                        (recursive)\n",
              "│    │    └─MaxPool1d: 3-12                        [64, 128, 64]             --\n",
              "│    └─Sequential: 2-8                             [64, 128, 16]             --\n",
              "│    │    └─Conv1d: 3-13                           [64, 64, 61]              25,600\n",
              "│    │    └─BatchNorm1d: 3-14                      [64, 64, 61]              128\n",
              "│    │    └─GELU: 3-15                             [64, 64, 61]              --\n",
              "│    │    └─MaxPool1d: 3-16                        [64, 64, 31]              --\n",
              "│    │    └─Dropout: 3-17                          [64, 64, 31]              --\n",
              "│    │    └─Conv1d: 3-18                           [64, 128, 31]             57,344\n",
              "│    │    └─BatchNorm1d: 3-19                      [64, 128, 31]             256\n",
              "│    │    └─GELU: 3-20                             [64, 128, 31]             --\n",
              "│    │    └─Conv1d: 3-21                           [64, 128, 31]             114,688\n",
              "│    │    └─BatchNorm1d: 3-22                      [64, 128, 31]             256\n",
              "│    │    └─GELU: 3-23                             [64, 128, 31]             --\n",
              "│    │    └─MaxPool1d: 3-24                        [64, 128, 16]             --\n",
              "│    └─Dropout: 2-9                                [64, 128, 80]             --\n",
              "│    └─Sequential: 2-10                            [64, 30, 80]              --\n",
              "│    │    └─SEBasicBlock: 3-25                     [64, 30, 80]              8,880\n",
              "├─TCE: 1-2                                         [64, 30, 80]              --\n",
              "│    └─ModuleList: 2-11                            --                        --\n",
              "│    │    └─EncoderLayer: 3-26                     [64, 30, 80]              51,520\n",
              "│    │    └─EncoderLayer: 3-27                     [64, 30, 80]              51,520\n",
              "│    └─LayerNorm: 2-12                             [64, 30, 80]              160\n",
              "├─Linear: 1-3                                      [64, 5]                   12,005\n",
              "====================================================================================================\n",
              "Total params: 719,925\n",
              "Trainable params: 719,925\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 3.97\n",
              "====================================================================================================\n",
              "Input size (MB): 0.77\n",
              "Forward/backward pass size (MB): 140.59\n",
              "Params size (MB): 2.04\n",
              "Estimated Total Size (MB): 143.40\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}